{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10605005,"sourceType":"datasetVersion","datasetId":6564727},{"sourceId":272758,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":233536,"modelId":255259}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import subprocess\nimport sys\n\n\nsubprocess.run(\"pip install datasets nltk gensim einops evaluate\", shell=True)\nsubprocess.run(\"python -m nltk.downloader punkt\", shell=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:39:39.972002Z","iopub.execute_input":"2025-03-02T12:39:39.972357Z","iopub.status.idle":"2025-03-02T12:39:46.118893Z","shell.execute_reply.started":"2025-03-02T12:39:39.972305Z","shell.execute_reply":"2025-03-02T12:39:46.117952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport nltk\nimport einops\nimport evaluate\ndevice = torch.device('cuda')\n\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:39:51.450432Z","iopub.execute_input":"2025-03-02T12:39:51.450877Z","iopub.status.idle":"2025-03-02T12:40:13.121108Z","shell.execute_reply.started":"2025-03-02T12:39:51.450840Z","shell.execute_reply":"2025-03-02T12:40:13.120464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wmt14 = load_dataset(\"wmt14\", \"de-en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:13.122216Z","iopub.execute_input":"2025-03-02T12:40:13.122755Z","iopub.status.idle":"2025-03-02T12:40:25.389607Z","shell.execute_reply.started":"2025-03-02T12:40:13.122719Z","shell.execute_reply":"2025-03-02T12:40:25.388622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = nltk.WordPunctTokenizer()\nlemmatizer = nltk.WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:25.391449Z","iopub.execute_input":"2025-03-02T12:40:25.391841Z","iopub.status.idle":"2025-03-02T12:40:25.396232Z","shell.execute_reply.started":"2025-03-02T12:40:25.391808Z","shell.execute_reply":"2025-03-02T12:40:25.395260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_pipeline(sentence):\n    tokens= tokenizer.tokenize(sentence)\n    return [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:25.397732Z","iopub.execute_input":"2025-03-02T12:40:25.398052Z","iopub.status.idle":"2025-03-02T12:40:26.851956Z","shell.execute_reply.started":"2025-03-02T12:40:25.398020Z","shell.execute_reply":"2025-03-02T12:40:26.850959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nimport subprocess\n\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n\nfrom nltk.corpus import wordnet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:26.852875Z","iopub.execute_input":"2025-03-02T12:40:26.853217Z","iopub.status.idle":"2025-03-02T12:40:28.315720Z","shell.execute_reply.started":"2025-03-02T12:40:26.853187Z","shell.execute_reply":"2025-03-02T12:40:28.314786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport kagglehub\ntokenizedwordsandids_path = kagglehub.dataset_download('maksshan/tokenizedwordsandids')\nwith open(f\"{tokenizedwordsandids_path}/all_tokenized_de_words\", 'r') as file1:\n    data = json.load(file1)\nall_tokenized_de_words = set(data)\nwith open(f\"{tokenizedwordsandids_path}/all_tokenized_en_words\", 'r') as file2:\n    data = json.load(file2)\nall_tokenized_en_words = set(data)\nen_words_to_ids = {word: idx + 16 for idx, word in enumerate(all_tokenized_en_words)}\nde_words_to_ids = {word: idx + 16 for idx, word in enumerate(all_tokenized_de_words)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:28.316649Z","iopub.execute_input":"2025-03-02T12:40:28.316987Z","iopub.status.idle":"2025-03-02T12:40:31.153937Z","shell.execute_reply.started":"2025-03-02T12:40:28.316965Z","shell.execute_reply":"2025-03-02T12:40:31.153203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\na = {'translation': wmt14['train']['translation'][:100000]}\na = Dataset.from_dict(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:31.154765Z","iopub.execute_input":"2025-03-02T12:40:31.154979Z","iopub.status.idle":"2025-03-02T12:40:59.472193Z","shell.execute_reply.started":"2025-03-02T12:40:31.154962Z","shell.execute_reply":"2025-03-02T12:40:59.471475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TranslationallDataset(torch.utils.data.Dataset):\n    def __init__(self, tokenizer, en_words_to_ids,de_words_to_ids, dataset, max_len=64):\n        self.tokenizer = tokenizer\n        self.en_words_to_ids = en_words_to_ids\n        self.de_words_to_ids = de_words_to_ids\n        def tokenizer_sentence(example):\n            return {'tokensen': self.tokenizer(example['translation']['en']), 'tokensde': self.tokenizer(example['translation']['de']) }\n        \n        def convert_words_to_ids(example):\n            return {'idsen': [self.en_words_to_ids[token] for token in example['tokensen']],'idsde': [self.de_words_to_ids[token] for token in example['tokensde']]}\n\n        dataset = dataset.map(tokenizer_sentence)\n\n        self.dataset = dataset.map(convert_words_to_ids)\n        self.max_len=64\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, index):\n        examplede = self.dataset[index]\n        lol1 = [1] + examplede['idsde'][:self.max_len-2] +[2]\n        if len(lol1)< self.max_len:\n            lol1 +=[0 for _ in range(self.max_len-len(lol1))] \n        exampleen = self.dataset[index]\n        lol2 = [1] + exampleen['idsen'][:self.max_len-2] +[2]\n        if len(lol2)< self.max_len:\n            lol2 +=[0 for _ in range(self.max_len-len(lol2))]\n        return torch.tensor(lol1),torch.tensor(lol2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:59.475071Z","iopub.execute_input":"2025-03-02T12:40:59.475372Z","iopub.status.idle":"2025-03-02T12:40:59.483027Z","shell.execute_reply.started":"2025-03-02T12:40:59.475350Z","shell.execute_reply":"2025-03-02T12:40:59.482365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = TranslationallDataset(tokenize_pipeline, en_words_to_ids,de_words_to_ids,a)\nvalid_dataset = TranslationallDataset(tokenize_pipeline, en_words_to_ids,de_words_to_ids,wmt14['validation'])\ntest_dataset = TranslationallDataset(tokenize_pipeline, en_words_to_ids,de_words_to_ids,wmt14['test'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:40:59.484330Z","iopub.execute_input":"2025-03-02T12:40:59.484542Z","iopub.status.idle":"2025-03-02T12:43:30.667281Z","shell.execute_reply.started":"2025-03-02T12:40:59.484524Z","shell.execute_reply":"2025-03-02T12:43:30.666399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(item):\n    x = torch.stack([i[0] for i in item])\n    y = torch.stack([i[1] for i in item])\n    return x,y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.668332Z","iopub.execute_input":"2025-03-02T12:43:30.668665Z","iopub.status.idle":"2025-03-02T12:43:30.672909Z","shell.execute_reply.started":"2025-03-02T12:43:30.668629Z","shell.execute_reply":"2025-03-02T12:43:30.671997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = 2, collate_fn=collate_fn)\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset,batch_size = 2, collate_fn=collate_fn)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size = 2, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.673792Z","iopub.execute_input":"2025-03-02T12:43:30.674085Z","iopub.status.idle":"2025-03-02T12:43:30.695902Z","shell.execute_reply.started":"2025-03-02T12:43:30.674053Z","shell.execute_reply":"2025-03-02T12:43:30.695135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example = next(iter(train_dataloader))\nexample[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.696843Z","iopub.execute_input":"2025-03-02T12:43:30.697076Z","iopub.status.idle":"2025-03-02T12:43:30.757718Z","shell.execute_reply.started":"2025-03-02T12:43:30.697057Z","shell.execute_reply":"2025-03-02T12:43:30.757145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model\n","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(torch.nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        self.W_q = torch.nn.Linear(d_model, d_model)\n        self.W_k = torch.nn.Linear(d_model, d_model)\n        self.W_v = torch.nn.Linear(d_model, d_model)\n        self.W_o = torch.nn.Linear(d_model, d_model)\n        \n    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        output = torch.matmul(attn_probs, V)\n        return output\n        \n    def split_heads(self, x):\n        batch_size, seq_length, d_model = x.size()\n        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n        \n    def combine_heads(self, x):\n        batch_size, _, seq_length, d_k = x.size()\n        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n        \n    def forward(self, Q, K, V, mask=None):\n        Q = self.split_heads(self.W_q(Q))\n        K = self.split_heads(self.W_k(K))\n        V = self.split_heads(self.W_v(V))\n        \n        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n        output = self.W_o(self.combine_heads(attn_output))\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.758439Z","iopub.execute_input":"2025-03-02T12:43:30.758751Z","iopub.status.idle":"2025-03-02T12:43:30.766827Z","shell.execute_reply.started":"2025-03-02T12:43:30.758731Z","shell.execute_reply":"2025-03-02T12:43:30.766135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nclass MLP(torch.nn.Module):\n    def __init__(self,hidden_dim:int):\n        super().__init__()\n\n        self.linear_0 = torch.nn.Linear(hidden_dim,2*hidden_dim)\n        self.linear_1 = torch.nn.Linear(2*hidden_dim,hidden_dim)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self,hidden_state):\n        return self.linear_1(self.relu(self.linear_0(hidden_state))) + hidden_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.767622Z","iopub.execute_input":"2025-03-02T12:43:30.767934Z","iopub.status.idle":"2025-03-02T12:43:30.783793Z","shell.execute_reply.started":"2025-03-02T12:43:30.767895Z","shell.execute_reply":"2025-03-02T12:43:30.782922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EncoderTransformerLayer(torch.nn.Module):\n    def __init__(self, hidden_dim: int, num_heads:int):\n        super().__init__()\n\n        self.attention_layer = MultiHeadAttention(hidden_dim,num_heads)\n        self.mlp_layer = MLP(hidden_dim)\n        self.layer_norm = torch.nn.LayerNorm(hidden_dim)\n        self.dropout = torch.nn.Dropout(p=0.25)\n        self.norm1 = torch.nn.LayerNorm(hidden_dim)\n        self.norm2 = torch.nn.LayerNorm(hidden_dim)\n    def forward(self, hidden_state,src_mask):\n        attn_output = self.attention_layer(hidden_state, hidden_state, hidden_state,mask = src_mask)\n        hidden_state = self.norm1(hidden_state + self.dropout(attn_output))\n        mlp_output = self.mlp_layer(hidden_state)\n        hidden_state = self.norm2(hidden_state + self.dropout(mlp_output))\n        return hidden_state\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.784605Z","iopub.execute_input":"2025-03-02T12:43:30.784834Z","iopub.status.idle":"2025-03-02T12:43:30.801996Z","shell.execute_reply.started":"2025-03-02T12:43:30.784804Z","shell.execute_reply":"2025-03-02T12:43:30.801446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DecoderTransformerLayer(torch.nn.Module):\n    def __init__(self, hidden_dim: int, num_heads:int):\n        super().__init__()\n\n        self.self_attention = MultiHeadAttention(hidden_dim,num_heads) #в переводе\n        self.out_attention = MultiHeadAttention(hidden_dim,num_heads)#в оригинале\n        self.mlp_layer = MLP(hidden_dim)\n        self.layer_norm = torch.nn.LayerNorm(hidden_dim)\n        self.dropout = torch.nn.Dropout(p=0.25)\n        self.norm1 = torch.nn.LayerNorm(hidden_dim)\n        self.norm2 = torch.nn.LayerNorm(hidden_dim)\n        self.norm3 = torch.nn.LayerNorm(hidden_dim)\n\n    def forward(self, inputs, encoder_layer_output,src_mask,tgt_mask):\n        masked_attn_output =  self.self_attention(inputs, inputs, inputs, mask=tgt_mask)\n        inputs = self.norm1(inputs + self.dropout(masked_attn_output))\n        \n        at = self.out_attention(inputs, encoder_layer_output, encoder_layer_output,mask=src_mask)\n        inputs = self.norm2(inputs + self.dropout(at))\n        asaf = self.mlp_layer(inputs)\n        inputs = self.norm3(inputs + self.dropout(asaf))\n        return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.802808Z","iopub.execute_input":"2025-03-02T12:43:30.803031Z","iopub.status.idle":"2025-03-02T12:43:30.818600Z","shell.execute_reply.started":"2025-03-02T12:43:30.803013Z","shell.execute_reply":"2025-03-02T12:43:30.817801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encoder(torch.nn.Module):\n    def __init__(self, de_dictionary_size: int, hidden_dim: int, num_heads,max_seq_len=64):\n        super().__init__()\n        \n        self.word_embedding = torch.nn.Embedding(de_dictionary_size,hidden_dim)\n        self.pos_embedding = torch.nn.Embedding(max_seq_len, hidden_dim)\n        \n        self.attention_layer0 = EncoderTransformerLayer(hidden_dim,num_heads)\n        self.attention_layer1 = EncoderTransformerLayer(hidden_dim,num_heads)\n        self.attention_layer2 = EncoderTransformerLayer(hidden_dim,num_heads)\n\n\n        \n    def forward(self, inputs,src_mask):\n        arange_tensor = torch.arange(inputs.size(-1))\n        word_embs = self.word_embedding(inputs)\n        pos_embs = self.pos_embedding(arange_tensor.to(device))\n        embs = word_embs + pos_embs\n        hidden_state = self.attention_layer0(embs,src_mask)\n        hidden_state = self.attention_layer1(hidden_state,src_mask)\n        hidden_state = self.attention_layer2(hidden_state,src_mask)\n\n        return hidden_state\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.819466Z","iopub.execute_input":"2025-03-02T12:43:30.819700Z","iopub.status.idle":"2025-03-02T12:43:30.841727Z","shell.execute_reply.started":"2025-03-02T12:43:30.819672Z","shell.execute_reply":"2025-03-02T12:43:30.840852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decoder(torch.nn.Module):\n    def __init__(self, en_dictionary_size: int, hidden_dim: int, num_heads,max_seq_len=64):\n        super().__init__()\n        self.num_heads = num_heads\n        self.word_embedding = torch.nn.Embedding(en_dictionary_size,hidden_dim)\n        self.pos_embedding = torch.nn.Embedding(max_seq_len, hidden_dim)\n        self.TransformerLayer = DecoderTransformerLayer(hidden_dim, num_heads)\n        self.TransformerLayer2 = DecoderTransformerLayer(hidden_dim, num_heads)\n        self.TransformerLayer3 = DecoderTransformerLayer(hidden_dim, num_heads)\n        self.lm_head = torch.nn.Linear(hidden_dim, en_dictionary_size)\n        \n    def forward(self, inputs, encoder_output,src_mask,tgt_mask):\n        arange_tensor = torch.arange(inputs.size(-1))\n        word_embs = self.word_embedding(inputs)\n        pos_embs = self.pos_embedding(arange_tensor.to(device))\n        embs = word_embs + pos_embs \n        hidden_state = self.TransformerLayer(embs,encoder_output,src_mask,tgt_mask)\n        hidden_state = self.TransformerLayer2(hidden_state,encoder_output,src_mask,tgt_mask)\n        hidden_state = self.TransformerLayer3(hidden_state,encoder_output,src_mask,tgt_mask)\n\n        \n        return self.lm_head(hidden_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.842644Z","iopub.execute_input":"2025-03-02T12:43:30.842910Z","iopub.status.idle":"2025-03-02T12:43:30.860185Z","shell.execute_reply.started":"2025-03-02T12:43:30.842890Z","shell.execute_reply":"2025-03-02T12:43:30.859419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TranslationModel(torch.nn.Module):\n    def __init__(self, de_dictionary_size: int, en_dictionary_size: int, hidden_dim: int, num_heads:int):\n        super().__init__()\n        self.num_heads=num_heads\n        self.encoder = Encoder(de_dictionary_size, hidden_dim,num_heads)\n        self.decoder = Decoder(en_dictionary_size, hidden_dim,num_heads)\n    def generate_mask(self, src, tgt):\n        src_mask = (src != PAD_TOKEN).unsqueeze(1).unsqueeze(2)\n        tgt_mask = (tgt != PAD_TOKEN).unsqueeze(1).unsqueeze(3)\n        seq_length = tgt.size(1)\n        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(next(self.parameters()).device)\n        tgt_mask = tgt_mask & nopeak_mask\n        return src_mask, tgt_mask\n    \n    def forward(self, original_ids,translation_ids):\n        src_mask, tgt_mask = self.generate_mask(original_ids, translation_ids)\n        encoder_output = self.encoder(original_ids.to(device),src_mask)\n        decoder_output = self.decoder(translation_ids.to(device), encoder_output,src_mask,tgt_mask)\n        return decoder_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.861011Z","iopub.execute_input":"2025-03-02T12:43:30.861287Z","iopub.status.idle":"2025-03-02T12:43:30.876562Z","shell.execute_reply.started":"2025-03-02T12:43:30.861256Z","shell.execute_reply":"2025-03-02T12:43:30.875752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.cuda.empty_cache()\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.877410Z","iopub.execute_input":"2025-03-02T12:43:30.877706Z","iopub.status.idle":"2025-03-02T12:43:30.950801Z","shell.execute_reply.started":"2025-03-02T12:43:30.877685Z","shell.execute_reply":"2025-03-02T12:43:30.950004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:30.951726Z","iopub.execute_input":"2025-03-02T12:43:30.952042Z","iopub.status.idle":"2025-03-02T12:43:31.192349Z","shell.execute_reply.started":"2025-03-02T12:43:30.952009Z","shell.execute_reply":"2025-03-02T12:43:31.191259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = TranslationModel((len(all_tokenized_de_words)),(len(all_tokenized_en_words)),hidden_dim=54,num_heads=3)\nmodel = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\ncriterion = torch.nn.CrossEntropyLoss()\nPAD_TOKEN = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:31.193591Z","iopub.execute_input":"2025-03-02T12:43:31.193897Z","iopub.status.idle":"2025-03-02T12:43:33.032049Z","shell.execute_reply.started":"2025-03-02T12:43:31.193845Z","shell.execute_reply":"2025-03-02T12:43:33.031390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from functools import reduce\n\ndef get_num_of_params(\n    model : torch.nn.Module\n) -> int:\n    return sum([reduce(lambda x, y: x * y, cur.shape) for cur in model.parameters()])\n\nget_num_of_params(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:33.034971Z","iopub.execute_input":"2025-03-02T12:43:33.035226Z","iopub.status.idle":"2025-03-02T12:43:33.041664Z","shell.execute_reply.started":"2025-03-02T12:43:33.035205Z","shell.execute_reply":"2025-03-02T12:43:33.040960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:33.042569Z","iopub.execute_input":"2025-03-02T12:43:33.042773Z","iopub.status.idle":"2025-03-02T12:43:33.060892Z","shell.execute_reply.started":"2025-03-02T12:43:33.042756Z","shell.execute_reply":"2025-03-02T12:43:33.059992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\ntrain_loss =[]\nvalid_loss =[]\nepochs = 1\nfor epoch in tqdm(range(epochs)):\n    model.train()\n    train_loss_current = []\n    model.train()\n    for idx, (X, y) in tqdm(enumerate(train_dataloader)):\n        preds = model(\n            X.to(device),\n            y[:, :-1].to(device)\n        )\n        loss = criterion(\n            preds.view(-1, len(all_tokenized_en_words)), \n            y.contiguous()[:, 1:].reshape(-1).to(device)\n        )\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()  \n        train_loss_current.append(loss.item())\n\n    train_loss.append(np.mean(train_loss_current))\n    \n    valid_loss_current = []\n    model.eval()\n    with torch.inference_mode():\n        for idx, (X, y) in enumerate(valid_dataloader):\n            preds = model(\n                X.to(device),\n                y[:, :-1].to(device)\n            )\n            loss = criterion(\n                preds.view(-1, len(all_tokenized_en_words)), \n                y.contiguous()[:, 1:].reshape(-1).to(device)\n            )  \n            valid_loss_current.append(loss.item())\n    valid_loss.append(np.mean(valid_loss_current))\n    \n    print(f'Эпоха - {epoch+1}, train_loss - {train_loss[-1]}, valid_loss - {valid_loss[-1]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:43:45.560023Z","iopub.execute_input":"2025-03-02T12:43:45.560396Z","iopub.status.idle":"2025-03-02T13:28:38.925493Z","shell.execute_reply.started":"2025-03-02T12:43:45.560360Z","shell.execute_reply":"2025-03-02T13:28:38.924466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#f= '/kaggle/working/DeepLByMeMax.model'\n#torch.save(model.state_dict(), f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model.load_state_dict(torch.load('/kaggle/input/deppl/pytorch/default/1/DeepLByMeMax.model', weights_only=True,map_location=torch.device('cpu')))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:40.042500Z","iopub.execute_input":"2025-03-02T13:36:40.042836Z","iopub.status.idle":"2025-03-02T13:36:40.049362Z","shell.execute_reply.started":"2025-03-02T13:36:40.042812Z","shell.execute_reply":"2025-03-02T13:36:40.048599Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepross(original,max_len:int):\n    tokenized_original = tokenize_pipeline(original)\n    idx_org = [1]+[de_words_to_ids[token] for token in tokenized_original]+[2]\n    if len(idx_org)< max_len:\n            idx_org +=[0 for _ in range(max_len-len(idx_org))] \n    idx_org = torch.tensor(idx_org)     \n    return (idx_org)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:44.888370Z","iopub.execute_input":"2025-03-02T13:36:44.888687Z","iopub.status.idle":"2025-03-02T13:36:44.893461Z","shell.execute_reply.started":"2025-03-02T13:36:44.888662Z","shell.execute_reply":"2025-03-02T13:36:44.892659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_last_token_prediction(prefix, original, model):\n    output = model(original.unsqueeze(0),prefix)\n    max_token = torch.argmax(output,dim=-1)\n    return max_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:45.058454Z","iopub.execute_input":"2025-03-02T13:36:45.058765Z","iopub.status.idle":"2025-03-02T13:36:45.062952Z","shell.execute_reply.started":"2025-03-02T13:36:45.058743Z","shell.execute_reply":"2025-03-02T13:36:45.061935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_SEQ_LEN = 64\nBOS_TOKEN = 1\nEOS_TOKEN = 2\n@torch.inference_mode\ndef generate(\n    src : torch.Tensor\n) -> torch.Tensor:\n    \n    tokens = [BOS_TOKEN]\n    while len(tokens) < MAX_SEQ_LEN and tokens[-1] != EOS_TOKEN:\n        tokens.append(\n            model(\n                src.unsqueeze(0).to(device),\n                torch.tensor([tokens], dtype=torch.int64).to(device))[0, -1, :].argmax().item())\n    return torch.tensor(tokens, dtype=torch.int64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:45.200155Z","iopub.execute_input":"2025-03-02T13:36:45.200487Z","iopub.status.idle":"2025-03-02T13:36:45.205888Z","shell.execute_reply.started":"2025-03-02T13:36:45.200463Z","shell.execute_reply":"2025-03-02T13:36:45.205004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original = \"Ich liebe dich\"\norg_preprossed = prepross(original,max_len=64)\norg_preprossed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:46.592461Z","iopub.execute_input":"2025-03-02T13:36:46.592767Z","iopub.status.idle":"2025-03-02T13:36:46.604161Z","shell.execute_reply.started":"2025-03-02T13:36:46.592743Z","shell.execute_reply":"2025-03-02T13:36:46.603229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"translated = generate(org_preprossed)\ntranslated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:49.064423Z","iopub.execute_input":"2025-03-02T13:36:49.064754Z","iopub.status.idle":"2025-03-02T13:36:49.238939Z","shell.execute_reply.started":"2025-03-02T13:36:49.064716Z","shell.execute_reply":"2025-03-02T13:36:49.238204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dec(tokens):\n    decoded = []\n    for i in tokens: \n        key = next((key for key, value in en_words_to_ids.items() if value == i), None)\n        decoded.append(key)\n    return decoded ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:51.526411Z","iopub.execute_input":"2025-03-02T13:36:51.526733Z","iopub.status.idle":"2025-03-02T13:36:51.530945Z","shell.execute_reply.started":"2025-03-02T13:36:51.526706Z","shell.execute_reply":"2025-03-02T13:36:51.530049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"d = dec(translated)\ne = ' '.join(d[1:-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:36:51.682275Z","iopub.execute_input":"2025-03-02T13:36:51.682614Z","iopub.status.idle":"2025-03-02T13:37:16.803254Z","shell.execute_reply.started":"2025-03-02T13:36:51.682586Z","shell.execute_reply":"2025-03-02T13:37:16.802113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Исходный текст: {original}')\nprint(f'Перевод: {e}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T13:37:22.691919Z","iopub.execute_input":"2025-03-02T13:37:22.692239Z","iopub.status.idle":"2025-03-02T13:37:22.696865Z","shell.execute_reply.started":"2025-03-02T13:37:22.692215Z","shell.execute_reply":"2025-03-02T13:37:22.695960Z"}},"outputs":[],"execution_count":null}]}